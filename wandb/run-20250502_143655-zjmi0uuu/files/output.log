Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Validation DataLoader 0:   0%|                                                                                                                                                                                                         | 0/1867 [00:00<?, ?it/s]
[VALIDATION] Batch 0 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.8460, max=1.0018
[VALIDATION] Reference: min=-0.9751, max=0.9976
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9751, max=0.9976, mean=-0.0001, std=0.2598
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9692, max=0.9917, mean=-0.0001, std=0.2598
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 0 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 160000])
[CLAP PIPELINE] Sample 0: 10004/160000 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   0%|                                                                                                                                                                                                 | 1/1867 [00:01<32:33,  0.96it/s]
[VALIDATION] Batch 1 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9942, max=0.9894
[VALIDATION] Reference: min=-0.9515, max=1.0022
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9515, max=1.0022, mean=-0.0000, std=0.0170
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9478, max=1.0039, mean=-0.0000, std=0.0170
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 150951 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 9049])
[CLAP PIPELINE] Sample 0: 1049/9049 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   0%|▏                                                                                                                                                                                              | 2/1867 [00:13<3:22:53,  0.15it/s]
[VALIDATION] Batch 2 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9974, max=0.8604
[VALIDATION] Reference: min=-0.9783, max=0.9732
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9783, max=0.9732, mean=-0.0000, std=0.0987
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9448, max=0.9648, mean=-0.0000, std=0.0987
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 50916 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 109084])
[CLAP PIPELINE] Sample 0: 21505/109084 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   0%|▎                                                                                                                                                                                              | 3/1867 [00:16<2:54:56,  0.18it/s]
[VALIDATION] Batch 3 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-1.0061, max=0.8718
[VALIDATION] Reference: min=-0.7937, max=1.0061
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.7937, max=1.0061, mean=-0.0000, std=0.1177
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.7939, max=0.9849, mean=-0.0000, std=0.1177
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 39821 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 120179])
[CLAP PIPELINE] Sample 0: 2976/120179 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   0%|▍                                                                                                                                                                                              | 4/1867 [00:20<2:36:24,  0.20it/s]
[VALIDATION] Batch 4 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.5586, max=0.9999
[VALIDATION] Reference: min=-0.9994, max=0.9963
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9994, max=0.9963, mean=0.0246, std=0.3379
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9888, max=0.9971, mean=0.0246, std=0.3381
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 63824 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 96176])
[CLAP PIPELINE] Sample 0: 129/96176 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   0%|▌                                                                                                                                                                                              | 5/1867 [00:25<2:36:51,  0.20it/s]
[VALIDATION] Batch 5 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9995, max=0.9186
[VALIDATION] Reference: min=-0.9782, max=0.6285
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9782, max=0.6285, mean=-0.0000, std=0.0403
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.8354, max=0.4902, mean=-0.0000, std=0.0275
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 53130 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 106870])
[CLAP PIPELINE] Sample 0: 3251/106870 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   0%|▌                                                                                                                                                                                              | 6/1867 [00:29<2:33:11,  0.20it/s]
[VALIDATION] Batch 6 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9642, max=0.9850
[VALIDATION] Reference: min=-0.9922, max=0.9958
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9922, max=0.9958, mean=-0.0065, std=0.3450
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9897, max=1.0088, mean=-0.0065, std=0.3450
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 29573 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 130427])
[CLAP PIPELINE] Sample 0: 12702/130427 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   0%|▋                                                                                                                                                                                              | 7/1867 [00:32<2:21:49,  0.22it/s]
[VALIDATION] Batch 7 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9989, max=0.9939
[VALIDATION] Reference: min=-0.9893, max=1.0040
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9893, max=1.0040, mean=0.0002, std=0.0502
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9502, max=0.9209, mean=0.0002, std=0.0501
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 157794 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 2206])
[CLAP PIPELINE] Sample 0: 31/2206 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   0%|▊                                                                                                                                                                                              | 8/1867 [00:45<2:58:04,  0.17it/s]
[VALIDATION] Batch 8 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9399, max=1.0021
[VALIDATION] Reference: min=-0.9285, max=0.9992
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9285, max=0.9992, mean=-0.0009, std=0.0743
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9150, max=1.0010, mean=-0.0009, std=0.0743
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 129720 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 30280])
[CLAP PIPELINE] Sample 0: 421/30280 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   0%|▉                                                                                                                                                                                              | 9/1867 [00:57<3:19:00,  0.16it/s]
[VALIDATION] Batch 9 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-1.0310, max=0.9746
[VALIDATION] Reference: min=-0.9640, max=0.5638
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9640, max=0.5638, mean=0.0001, std=0.0611
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9619, max=0.5381, mean=0.0001, std=0.0578
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 64501 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 95499])
[CLAP PIPELINE] Sample 0: 1075/95499 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   1%|█                                                                                                                                                                                             | 10/1867 [01:03<3:16:31,  0.16it/s]
[VALIDATION] Batch 10 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9288, max=1.0148
[VALIDATION] Reference: min=-0.9982, max=0.8683
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9982, max=0.8683, mean=-0.0054, std=0.0859
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9937, max=0.8677, mean=-0.0054, std=0.0859
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 127119 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 32881])
[CLAP PIPELINE] Sample 0: 2442/32881 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   1%|█                                                                                                                                                                                             | 11/1867 [01:14<3:29:51,  0.15it/s]
[VALIDATION] Batch 11 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.4827, max=0.9970
[VALIDATION] Reference: min=-0.9793, max=0.9997
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9793, max=0.9997, mean=0.0003, std=0.1813
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9644, max=0.9917, mean=0.0003, std=0.1813
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 69164 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 90836])
[CLAP PIPELINE] Sample 0: 302/90836 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   1%|█▏                                                                                                                                                                                            | 12/1867 [01:20<3:27:15,  0.15it/s]
[VALIDATION] Batch 12 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-1.0314, max=0.9522
[VALIDATION] Reference: min=-1.0045, max=1.0056
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-1.0045, max=1.0056, mean=-0.0264, std=0.5016
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-1.0049, max=1.0166, mean=-0.0264, std=0.5015
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 48158 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 111842])
[CLAP PIPELINE] Sample 0: 723/111842 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   1%|█▎                                                                                                                                                                                            | 13/1867 [01:24<3:20:39,  0.15it/s]
[VALIDATION] Batch 13 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.7462, max=0.9987
[VALIDATION] Reference: min=-0.9926, max=0.9998
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9926, max=0.9998, mean=0.0003, std=0.1458
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9932, max=1.0010, mean=0.0003, std=0.1459
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 26860 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 133140])
[CLAP PIPELINE] Sample 0: 5671/133140 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   1%|█▍                                                                                                                                                                                            | 14/1867 [01:26<3:11:00,  0.16it/s]
[VALIDATION] Batch 14 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9781, max=0.9986
[VALIDATION] Reference: min=-0.9013, max=1.0021
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9013, max=1.0021, mean=-0.0000, std=0.0761
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.8965, max=0.9722, mean=-0.0000, std=0.0760
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 142031 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 17969])
[CLAP PIPELINE] Sample 0: 1530/17969 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   1%|█▌                                                                                                                                                                                            | 15/1867 [01:39<3:25:05,  0.15it/s]
[VALIDATION] Batch 15 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-1.0257, max=1.0054
[VALIDATION] Reference: min=-0.7116, max=0.9945
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.7116, max=0.9945, mean=-0.0000, std=0.0276
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.6792, max=0.9692, mean=-0.0000, std=0.0276
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 88569 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 71431])
[CLAP PIPELINE] Sample 0: 23590/71431 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   1%|█▋                                                                                                                                                                                            | 16/1867 [01:47<3:27:08,  0.15it/s]
[VALIDATION] Batch 16 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9718, max=0.9924
[VALIDATION] Reference: min=-0.9974, max=0.8624
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9974, max=0.8624, mean=-0.0012, std=0.0975
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9082, max=0.8745, mean=-0.0012, std=0.0951
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 99069 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 60931])
[CLAP PIPELINE] Sample 0: 1307/60931 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   1%|█▋                                                                                                                                                                                            | 17/1867 [01:56<3:30:29,  0.15it/s]
[VALIDATION] Batch 17 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9878, max=0.8053
[VALIDATION] Reference: min=-0.9999, max=0.8706
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9999, max=0.8706, mean=-0.0054, std=0.1878
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-1.0010, max=0.8677, mean=-0.0054, std=0.1879
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 79856 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 80144])
[CLAP PIPELINE] Sample 0: 679/80144 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   1%|█▊                                                                                                                                                                                            | 18/1867 [02:03<3:30:56,  0.15it/s]
[VALIDATION] Batch 18 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9944, max=0.9682
[VALIDATION] Reference: min=-0.9987, max=0.9999
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9987, max=0.9999, mean=0.0000, std=0.0938
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9805, max=0.9829, mean=0.0000, std=0.0938
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 119878 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 40122])
[CLAP PIPELINE] Sample 0: 1827/40122 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   1%|█▉                                                                                                                                                                                            | 19/1867 [02:13<3:37:04,  0.14it/s]
[VALIDATION] Batch 19 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-1.0067, max=0.8112
[VALIDATION] Reference: min=-0.9761, max=0.9236
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9761, max=0.9236, mean=-0.0016, std=0.0649
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.5703, max=0.6548, mean=-0.0016, std=0.0616
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 49358 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 110642])
[CLAP PIPELINE] Sample 0: 1360/110642 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   1%|██                                                                                                                                                                                            | 20/1867 [02:17<3:32:20,  0.14it/s]
[VALIDATION] Batch 20 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.6583, max=0.9988
[VALIDATION] Reference: min=-0.9974, max=1.0003
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9974, max=1.0003, mean=0.0079, std=0.1641
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9976, max=1.0000, mean=0.0079, std=0.1641
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 95402 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 64598])
[CLAP PIPELINE] Sample 0: 302/64598 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   1%|██▏                                                                                                                                                                                           | 21/1867 [02:26<3:34:22,  0.14it/s]
[VALIDATION] Batch 21 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-1.0204, max=0.7858
[VALIDATION] Reference: min=-0.8219, max=0.8306
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.8219, max=0.8306, mean=-0.0000, std=0.0854
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.7202, max=0.7139, mean=-0.0000, std=0.0742
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 0 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 160000])
[CLAP PIPELINE] Sample 0: 3367/160000 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   1%|██▏                                                                                                                                                                                           | 22/1867 [02:26<3:24:44,  0.15it/s]
[VALIDATION] Batch 22 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9936, max=0.9586
[VALIDATION] Reference: min=-1.0236, max=0.8598
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-1.0236, max=0.8598, mean=-0.0000, std=0.0502
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.7427, max=0.5659, mean=-0.0000, std=0.0434
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 47740 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 112260])
[CLAP PIPELINE] Sample 0: 1755/112260 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   1%|██▎                                                                                                                                                                                           | 23/1867 [02:30<3:20:39,  0.15it/s]
[VALIDATION] Batch 23 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.8870, max=0.9910
[VALIDATION] Reference: min=-0.9991, max=0.9868
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9991, max=0.9868, mean=-0.0023, std=0.0904
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-1.0039, max=0.9937, mean=-0.0023, std=0.0904
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 136500 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 23500])
[CLAP PIPELINE] Sample 0: 287/23500 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   1%|██▍                                                                                                                                                                                           | 24/1867 [02:42<3:28:01,  0.15it/s]
[VALIDATION] Batch 24 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-1.2777, max=1.2719
[VALIDATION] Reference: min=-0.8681, max=0.9757
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.8681, max=0.9757, mean=0.0000, std=0.1035
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.7969, max=0.9199, mean=0.0000, std=0.0999
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 99761 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 60239])
[CLAP PIPELINE] Sample 0: 4299/60239 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   1%|██▌                                                                                                                                                                                           | 25/1867 [02:50<3:29:39,  0.15it/s]
[VALIDATION] Batch 25 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-1.0002, max=0.9217
[VALIDATION] Reference: min=-0.9952, max=0.9767
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9952, max=0.9767, mean=-0.0001, std=0.0806
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-1.0000, max=0.9756, mean=-0.0001, std=0.0806
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 140479 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 19521])
[CLAP PIPELINE] Sample 0: 460/19521 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   1%|██▋                                                                                                                                                                                           | 26/1867 [03:02<3:35:31,  0.14it/s]
[VALIDATION] Batch 26 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-1.0024, max=0.8892
[VALIDATION] Reference: min=-1.0035, max=0.9343
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-1.0035, max=0.9343, mean=-0.0000, std=0.0918
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9531, max=0.9155, mean=-0.0000, std=0.0916
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 114279 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 45721])
[CLAP PIPELINE] Sample 0: 2297/45721 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   1%|██▋                                                                                                                                                                                           | 27/1867 [03:12<3:38:14,  0.14it/s]
[VALIDATION] Batch 27 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.8050, max=1.0003
[VALIDATION] Reference: min=-0.9679, max=0.8830
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9679, max=0.8830, mean=-0.0000, std=0.1439
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9243, max=0.8379, mean=-0.0000, std=0.1431
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 63687 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 96313])
[CLAP PIPELINE] Sample 0: 927/96313 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   1%|██▊                                                                                                                                                                                           | 28/1867 [03:17<3:35:59,  0.14it/s]
[VALIDATION] Batch 28 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.5209, max=1.0051
[VALIDATION] Reference: min=-0.3257, max=0.5664
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.3257, max=0.5664, mean=-0.0000, std=0.0078
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.2211, max=0.3230, mean=-0.0000, std=0.0060
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 139169 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 20831])
[CLAP PIPELINE] Sample 0: 1738/20831 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   2%|██▉                                                                                                                                                                                           | 29/1867 [03:29<3:41:07,  0.14it/s]
[VALIDATION] Batch 29 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.8601, max=0.8796
[VALIDATION] Reference: min=-0.9712, max=0.9934
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9712, max=0.9934, mean=0.0001, std=0.1661
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9746, max=0.9736, mean=0.0001, std=0.1495
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 0 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 160000])
[CLAP PIPELINE] Sample 0: 3035/160000 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   2%|███                                                                                                                                                                                           | 30/1867 [03:29<3:33:52,  0.14it/s]
[VALIDATION] Batch 30 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-1.0008, max=0.9850
[VALIDATION] Reference: min=-0.9271, max=0.9994
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9271, max=0.9994, mean=-0.0000, std=0.1637
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9277, max=1.0000, mean=-0.0000, std=0.1638
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 83228 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 76772])
[CLAP PIPELINE] Sample 0: 665/76772 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   2%|███▏                                                                                                                                                                                          | 31/1867 [03:36<3:34:00,  0.14it/s]
[VALIDATION] Batch 31 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9301, max=0.9985
[VALIDATION] Reference: min=-0.9845, max=0.9903
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9845, max=0.9903, mean=0.0000, std=0.0162
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9717, max=0.9814, mean=0.0000, std=0.0160
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 152399 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 7601])
[CLAP PIPELINE] Sample 0: 2349/7601 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   2%|███▎                                                                                                                                                                                          | 32/1867 [03:50<3:40:06,  0.14it/s]
[VALIDATION] Batch 32 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-1.0033, max=0.8693
[VALIDATION] Reference: min=-0.9937, max=1.0002
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9937, max=1.0002, mean=0.0001, std=0.1020
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9941, max=1.0000, mean=0.0001, std=0.1021
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 112159 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 47841])
[CLAP PIPELINE] Sample 0: 868/47841 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   2%|███▎                                                                                                                                                                                          | 33/1867 [03:59<3:42:14,  0.14it/s]
[VALIDATION] Batch 33 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.6672, max=0.9998
[VALIDATION] Reference: min=-0.7952, max=1.0002
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.7952, max=1.0002, mean=-0.0003, std=0.0798
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.7959, max=0.9995, mean=-0.0003, std=0.0798
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 97633 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 62367])
[CLAP PIPELINE] Sample 0: 3911/62367 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   2%|███▍                                                                                                                                                                                          | 34/1867 [04:08<3:43:32,  0.14it/s]
[VALIDATION] Batch 34 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9635, max=0.5665
[VALIDATION] Reference: min=-1.0308, max=1.0208
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-1.0308, max=1.0208, mean=0.0000, std=0.2349
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-1.0732, max=1.0781, mean=0.0000, std=0.2347
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 110832 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 49168])
[CLAP PIPELINE] Sample 0: 1591/49168 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   2%|███▌                                                                                                                                                                                          | 35/1867 [04:18<3:45:19,  0.14it/s]
[VALIDATION] Batch 35 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9779, max=1.0000
[VALIDATION] Reference: min=-1.0019, max=0.9717
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-1.0019, max=0.9717, mean=0.0000, std=0.1093
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9746, max=0.9976, mean=0.0000, std=0.1088
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 129987 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 30013])
[CLAP PIPELINE] Sample 0: 787/30013 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   2%|███▋                                                                                                                                                                                          | 36/1867 [04:29<3:48:16,  0.13it/s]
[VALIDATION] Batch 36 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.7744, max=0.9956
[VALIDATION] Reference: min=-0.9995, max=0.7863
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9995, max=0.7863, mean=-0.0000, std=0.0185
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9990, max=0.7861, mean=-0.0000, std=0.0185
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 114248 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 45752])
[CLAP PIPELINE] Sample 0: 14968/45752 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   2%|███▊                                                                                                                                                                                          | 37/1867 [04:38<3:49:30,  0.13it/s]
[VALIDATION] Batch 37 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9642, max=0.9935
[VALIDATION] Reference: min=-1.0035, max=0.9343
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-1.0035, max=0.9343, mean=-0.0000, std=0.0918
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9531, max=0.9155, mean=-0.0000, std=0.0916
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 114279 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 45721])
[CLAP PIPELINE] Sample 0: 2297/45721 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   2%|███▊                                                                                                                                                                                          | 38/1867 [04:47<3:50:40,  0.13it/s]
[VALIDATION] Batch 38 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9917, max=0.9447
[VALIDATION] Reference: min=-0.8880, max=0.9406
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.8880, max=0.9406, mean=-0.0003, std=0.1273
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.7573, max=0.8618, mean=-0.0003, std=0.1118
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 64091 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 95909])
[CLAP PIPELINE] Sample 0: 543/95909 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   2%|███▉                                                                                                                                                                                          | 39/1867 [04:52<3:48:25,  0.13it/s]
[VALIDATION] Batch 39 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.8392, max=1.0050
[VALIDATION] Reference: min=-0.9967, max=0.8892
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9967, max=0.8892, mean=-0.0005, std=0.1574
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9980, max=0.8481, mean=-0.0005, std=0.1570
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 12275 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 147725])
[CLAP PIPELINE] Sample 0: 1290/147725 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   2%|████                                                                                                                                                                                          | 40/1867 [04:53<3:43:21,  0.14it/s]
[VALIDATION] Batch 40 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.8333, max=0.9989
[VALIDATION] Reference: min=-0.9528, max=0.9827
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9528, max=0.9827, mean=-0.0000, std=0.0774
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.4546, max=0.4751, mean=-0.0000, std=0.0529
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 28471 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 131529])
[CLAP PIPELINE] Sample 0: 17998/131529 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   2%|████▏                                                                                                                                                                                         | 41/1867 [04:55<3:39:31,  0.14it/s]
[VALIDATION] Batch 41 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9475, max=0.9995
[VALIDATION] Reference: min=-0.9991, max=0.9980
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9991, max=0.9980, mean=0.0001, std=0.3865
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9951, max=0.9985, mean=0.0001, std=0.3867
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 93894 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 66106])
[CLAP PIPELINE] Sample 0: 108/66106 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   2%|████▎                                                                                                                                                                                         | 42/1867 [05:03<3:39:40,  0.14it/s]
[VALIDATION] Batch 42 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-1.0003, max=0.9920
[VALIDATION] Reference: min=-1.0002, max=0.9456
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-1.0002, max=0.9456, mean=-0.0006, std=0.1208
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9902, max=0.9458, mean=-0.0006, std=0.1208
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 122112 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 37888])
[CLAP PIPELINE] Sample 0: 1061/37888 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   2%|████▍                                                                                                                                                                                         | 43/1867 [05:13<3:41:45,  0.14it/s]
[VALIDATION] Batch 43 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-1.0125, max=0.7752
[VALIDATION] Reference: min=-0.9922, max=0.9958
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9922, max=0.9958, mean=-0.0065, std=0.3450
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9897, max=1.0088, mean=-0.0065, std=0.3450
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 29573 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 130427])
[CLAP PIPELINE] Sample 0: 12702/130427 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   2%|████▍                                                                                                                                                                                         | 44/1867 [05:16<3:38:15,  0.14it/s]
[VALIDATION] Batch 44 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.8142, max=1.0001
[VALIDATION] Reference: min=-0.9993, max=0.9803
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9993, max=0.9803, mean=0.0000, std=0.1885
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9785, max=0.9771, mean=0.0000, std=0.1885
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 45498 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 114502])
[CLAP PIPELINE] Sample 0: 1261/114502 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   2%|████▌                                                                                                                                                                                         | 45/1867 [05:20<3:35:56,  0.14it/s]
[VALIDATION] Batch 45 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9540, max=0.9494
[VALIDATION] Reference: min=-0.8598, max=0.9947
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.8598, max=0.9947, mean=0.0000, std=0.0268
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.8584, max=0.9951, mean=0.0000, std=0.0268
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 136840 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 23160])
[CLAP PIPELINE] Sample 0: 2277/23160 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   2%|████▋                                                                                                                                                                                         | 46/1867 [05:31<3:38:50,  0.14it/s]
[VALIDATION] Batch 46 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.6682, max=1.0009
[VALIDATION] Reference: min=-0.4728, max=0.5440
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.4728, max=0.5440, mean=-0.0000, std=0.0156
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.3665, max=0.4004, mean=-0.0000, std=0.0115
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 107791 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 52209])
[CLAP PIPELINE] Sample 0: 4960/52209 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   3%|████▊                                                                                                                                                                                         | 47/1867 [05:41<3:40:10,  0.14it/s]
[VALIDATION] Batch 47 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9946, max=0.9790
[VALIDATION] Reference: min=-0.9917, max=0.9581
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9917, max=0.9581, mean=-0.0000, std=0.0719
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-1.0039, max=0.9253, mean=-0.0000, std=0.0718
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 99974 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 60026])
[CLAP PIPELINE] Sample 0: 32000/60026 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   3%|████▉                                                                                                                                                                                         | 48/1867 [05:49<3:40:40,  0.14it/s]
[VALIDATION] Batch 48 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9896, max=0.9396
[VALIDATION] Reference: min=-1.0533, max=1.0435
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-1.0533, max=1.0435, mean=0.0000, std=0.0677
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-1.0068, max=1.0635, mean=0.0000, std=0.0674
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 26195 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 133805])
[CLAP PIPELINE] Sample 0: 5838/133805 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   3%|████▉                                                                                                                                                                                         | 49/1867 [05:51<3:37:25,  0.14it/s]
[VALIDATION] Batch 49 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-1.0001, max=0.8927
[VALIDATION] Reference: min=-0.9809, max=0.9995
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9809, max=0.9995, mean=0.0000, std=0.2168
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9902, max=1.0068, mean=0.0000, std=0.2168
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 64000 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 96000])
[CLAP PIPELINE] Sample 0: 641/96000 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   3%|█████                                                                                                                                                                                         | 50/1867 [05:57<3:36:31,  0.14it/s]
[VALIDATION] Batch 50 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9944, max=0.8640
[VALIDATION] Reference: min=-0.9898, max=1.0118
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-0.9898, max=1.0118, mean=-0.0000, std=0.1608
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-1.0029, max=1.0391, mean=-0.0000, std=0.1609
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 76107 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 83893])
[CLAP PIPELINE] Sample 0: 6591/83893 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   3%|█████▏                                                                                                                                                                                        | 51/1867 [06:04<3:36:11,  0.14it/s]
[VALIDATION] Batch 51 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9999, max=0.8574
[VALIDATION] Reference: min=-1.0001, max=0.9950
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-1.0001, max=0.9950, mean=0.0001, std=0.2440
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-1.0010, max=0.9956, mean=0.0001, std=0.2441
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 93611 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 66389])
[CLAP PIPELINE] Sample 0: 63/66389 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   3%|█████▎                                                                                                                                                                                        | 52/1867 [06:12<3:36:50,  0.14it/s]
[VALIDATION] Batch 52 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-1.0299, max=1.0151
[VALIDATION] Reference: min=-1.0000, max=0.9993
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-1.0000, max=0.9993, mean=-0.0000, std=0.0946
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-1.0244, max=1.0166, mean=-0.0000, std=0.0945
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 140681 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 19319])
[CLAP PIPELINE] Sample 0: 904/19319 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   3%|█████▍                                                                                                                                                                                        | 53/1867 [06:25<3:39:41,  0.14it/s]
[VALIDATION] Batch 53 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.9017, max=0.9935
[VALIDATION] Reference: min=-1.0000, max=0.9993
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-1.0000, max=0.9993, mean=-0.0000, std=0.0946
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-1.0244, max=1.0166, mean=-0.0000, std=0.0945
[CLAP PIPELINE] Processing 1 samples individually
[CLAP PIPELINE] Removed 140681 trailing zeros from sample 0
[CLAP PIPELINE] Sample 0 shape: torch.Size([1, 19319])
[CLAP PIPELINE] Sample 0: 904/19319 near-zero values
[CLAP PIPELINE] Final embeddings batch shape: torch.Size([1, 512])
[CLAP PIPELINE] CLAP embedding shape: torch.Size([1, 512])
[CLAP PIPELINE] WARNING: CLAP embedding has 512/512 NaN values and 0/512 Inf values
[CLAP PIPELINE] CLAP embedding stats: min=nan, max=nan, mean=nan, std=nan
[CLAP PIPELINE] CLAP embedding norms: min=nan, max=nan, mean=nan
[VALIDATION] Shapes: y_im torch.Size([1, 512]), y_ref torch.Size([1, 512]), y_clap torch.Size([1, 512])
[VALIDATION] Norms: y_im 1.0000, y_ref 1.0000, y_clap nan
[VALIDATION] WARNING: y_clap has 512/512 NaN and 0/512 Inf
[VALIDATION] WARNING: NaN found in log_softmax outputs:
[VALIDATION]   - C_qvim_log: 0/1 NaN values
[VALIDATION]   - C_ref_clap_log: 1/1 NaN values
[VALIDATION]   - C_im_clap_log: 1/1 NaN values
Validation DataLoader 0:   3%|█████▍                                                                                                                                                                                        | 54/1867 [06:37<3:42:19,  0.14it/s]
[VALIDATION] Batch 54 - Processing validation data
[VALIDATION] Imitation shape: torch.Size([1, 320000]), Reference shape: torch.Size([1, 320000])
[VALIDATION] Imitation: min=-0.7136, max=0.9929
[VALIDATION] Reference: min=-1.0079, max=1.0084
[CLAP PIPELINE] Input audio shape: torch.Size([1, 320000])
[CLAP PIPELINE] Input audio stats: min=-1.0079, max=1.0084, mean=-0.0001, std=0.1935
[CLAP PIPELINE] After resampling: shape=torch.Size([1, 160000])
[CLAP PIPELINE] After resampling stats: min=-0.9668, max=0.9990, mean=-0.0001, std=0.1769
[CLAP PIPELINE] Processing 1 samples individually

Detected KeyboardInterrupt, attempting graceful shutdown ...
