Dataset directory ready at audioldm/qvim/data/Vim_Sketch_Dataset
Dataset directory ready at audioldm/qvim/data
Successfully loaded dataset with 12453 samples
Training with 11208 samples, validating with 1245 samples
Loading QVIM model from audioldm/qvim/models_vimsketch_longer/dulcet-leaf-31/best-loss-checkpoint.ckpt
Loading QVIM model from audioldm/qvim/models_vimsketch_longer/dulcet-leaf-31/best-loss-checkpoint.ckpt
Warning: FMAX is None setting to 15000
Initializing QVIM adapter: QVIM dim=960, AudioLDM dim=512
Loading AudioLDM model: audioldm-m-full
Load AudioLDM: %s audioldm-m-full
DiffusionWrapper has 415.95 M params.
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Replacing checkpoint function and CheckpointFunction class with training-compatible versions
Searching for and disabling ALL gradient checkpointing in the model...
Disabled gradient checkpointing in 0 modules
Unfroze 0 FiLM parameter tensors
Total FiLM parameters ufrozen: 0
Adapter has 1511936 trainable parameters
Total trainable parameters: 1511936
Modules in train mode: 8
Modules in eval mode: 2250
Using guidance scale scheduler: 1.0 → 3.0
  Warmup: 10.0% of training, Rampup: 40.0% of training
Saving checkpoints to run-specific directory: ckpt/vocaldm/firm-glitter-108
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
Parameter names saved to: ckpt/vocaldm/firm-glitter-108/model_parameters.txt
Simplified parameter blocks saved to: ckpt/vocaldm/firm-glitter-108/simplified_parameters.txt

===== Running initial validation for baseline metrics =====
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Validation DataLoader 0:   0%|▎                                                                                                                                                                                                                                       | 1/623 [00:06<1:02:26,  0.17it/s]Decoded mel shape: torch.Size([2, 1, 1024, 64])
DDIM Sampler: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:29<00:00,  3.40it/s]
DDIM Sampler: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:29<00:00,  3.77it/s]
Generated audio max abs value: 0.1506
Saved audio files for epoch 0, sample 0 to ckpt/vocaldm/firm-glitter-108/audio_logging
Generated audio max abs value: 0.3335
Saved audio files for epoch 0, sample 1 to ckpt/vocaldm/firm-glitter-108/audio_logging
Validation DataLoader 0:  20%|██████████████████████████████████████████████▌                                                                                                                                                                                         | 125/623 [01:35<06:22,  1.30it/s]Resources cleaned up
Detected KeyboardInterrupt, attempting graceful shutdown ...
