Saving checkpoints to run-specific directory: ckpt/vocaldm/kse6nqkf
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..

===== Running initial validation for baseline metrics =====
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Validation DataLoader 0:   0%|                                                                                                                                                                                             | 0/1 [00:00<?, ?it/s]Resampling audio from 32000Hz to 16000Hz
/mnt/c/Users/Davy/Documents/Code/QM/CC/AudioLDM/audioldm/audio/stft.py:42: FutureWarning: Pass size=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error
  fft_window = pad_center(fft_window, filter_length)
/mnt/c/Users/Davy/Documents/Code/QM/CC/AudioLDM/audioldm/audio/stft.py:145: FutureWarning: Pass sr=16000, n_fft=1024, n_mels=64, fmin=0, fmax=8000 as keyword args. From version 0.10 passing these as positional arguments will result in an error
  mel_basis = librosa_mel_fn(
Error in waveform_to_mel: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_bmm)
Falling back to placeholder method
DDIM Sampler: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:16<00:00,  3.08it/s]
Traceback (most recent call last):███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:16<00:00,  4.41it/s]
Error in audio logging: ushort format requires 0 <= number <= (0x7fff * 2 + 1)
  File "/mnt/c/Users/Davy/Documents/Code/QM/CC/AudioLDM/train_vocaldm.py", line 919, in log_audio_examples
    wavfile.write(generated_path, sample_rate, generated_audio_np.astype(np.float32))
  File "/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/scipy/io/wavfile.py", line 824, in write
    fmt_chunk_data = struct.pack('<HHIIHH', format_tag, channels, fs,
struct.error: ushort format requires 0 <= number <= (0x7fff * 2 + 1)
Validation DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:33<00:00,  0.03it/s]
Saved improved adapter to ckpt/vocaldm/qvim_adapter_val_loss_0.2865.pt
Validation DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:34<00:00,  0.03it/s]
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m [0m[1m     Validate metric     [0m[1m [0m┃[1m [0m[1m      DataLoader 0       [0m[1m [0m┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│[36m [0m[36m     val/cosine_loss     [0m[36m [0m│[35m [0m[35m           0.0           [0m[35m [0m│
│[36m [0m[36m     val/epoch_loss      [0m[36m [0m│[35m [0m[35m   0.2864980101585388    [0m[35m [0m│
│[36m [0m[36m        val/loss         [0m[36m [0m│[35m [0m[35m   0.2864980101585388    [0m[35m [0m│
│[36m [0m[36m      val/mse_loss       [0m[36m [0m│[35m [0m[35m   0.2864980101585388    [0m[35m [0m│
│[36m [0m[36m        val_loss         [0m[36m [0m│[35m [0m[35m   0.2864980101585388    [0m[35m [0m│
└───────────────────────────┴───────────────────────────┘
Initial validation loss: 0.286498
===== Initial validation complete =====
/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /mnt/c/Users/Davy/Documents/Code/QM/CC/AudioLDM/ckpt/vocaldm/kse6nqkf exists and is not empty.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name       | Type            | Params | Mode
-------------------------------------------------------
0 | qvim_model | QVIMModule      | 9.8 M  | eval
1 | adapter    | QVIMAdapter     | 1.5 M  | train
2 | audioldm   | LatentDiffusion | 726 M  | eval
-------------------------------------------------------
2.6 M     Trainable params
734 M     Non-trainable params
737 M     Total params
2,949.710 Total estimated model params size (MB)
12        Modules in train mode
2245      Modules in eval mode

Sanity Checking DataLoader 0:   0%|                                                                                                                                                                                        | 0/1 [00:00<?, ?it/s]Resampling audio from 32000Hz to 16000Hz
Error in waveform_to_mel: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_bmm)
Falling back to placeholder method
DDIM Sampler: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:11<00:00,  4.53it/s]
Traceback (most recent call last):███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:11<00:00,  4.94it/s]
Error in audio logging: ushort format requires 0 <= number <= (0x7fff * 2 + 1)
  File "/mnt/c/Users/Davy/Documents/Code/QM/CC/AudioLDM/train_vocaldm.py", line 919, in log_audio_examples
    wavfile.write(generated_path, sample_rate, generated_audio_np.astype(np.float32))
  File "/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/scipy/io/wavfile.py", line 824, in write
    fmt_chunk_data = struct.pack('<HHIIHH', format_tag, channels, fs,
struct.error: ushort format requires 0 <= number <= (0x7fff * 2 + 1)
Epoch 0:   0%|                                                                                                                                                                                                             | 0/2 [00:00<?, ?it/s]Resampling audio from 32000Hz to 16000Hz
/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:310: The number of training batches (2) is smaller than the logging interval Trainer(log_every_n_steps=10). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
Error in waveform_to_mel: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat2 in method wrapper_CUDA_bmm)
Falling back to placeholder method
diffusion_loss requires_grad: True
Checking gradient paths:
Component requires_grad check: {'squared_diff': True, 'model_output': True, 'target': False}
Epoch 0:  50%|█████████████████████████████████████████████████████████████                                                             | 1/2 [00:15<00:15,  0.06it/s, v_num=nqkf, train/loss=0.847, train/adapter_lr=0.0001, train/film_lr=1e-5]Resources cleaned up

Detected KeyboardInterrupt, attempting graceful shutdown ...
