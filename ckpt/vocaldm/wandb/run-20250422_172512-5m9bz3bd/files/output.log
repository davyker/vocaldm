audioldm/qvim/data/VimSketch.zip already exists. Skipping download. https://zenodo.org/records/2596911/files/Vim_Sketch_Dataset.zip?download=1
Vim_Sketch_Dataset already exists. Skipping extraction.
Dataset directory ready at audioldm/qvim/data
Successfully loaded dataset with 12453 samples
Training with 11208 samples, validating with 1245 samples
Loading QVIM model from audioldm/qvim/models_vimsketch_longer/dulcet-leaf-31/best-loss-checkpoint.ckpt
Loading QVIM model from audioldm/qvim/models_vimsketch_longer/dulcet-leaf-31/best-loss-checkpoint.ckpt
Warning: FMAX is None setting to 15000
/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/torchvision/ops/misc.py:120: UserWarning: Don't use ConvNormActivation directly, please use Conv2dNormActivation and Conv3dNormActivation instead.
  warnings.warn(
Initializing QVIM adapter: QVIM dim=960, AudioLDM dim=512
Loading AudioLDM model: audioldm-m-full
Load AudioLDM: %s audioldm-m-full
DiffusionWrapper has 415.95 M params.
/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/torchlibrosa/stft.py:193: FutureWarning: Pass size=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error
  fft_window = librosa.util.pad_center(fft_window, n_fft)
/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1742923400330/work/aten/src/ATen/native/TensorShape.cpp:3637.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Replacing checkpoint function and CheckpointFunction class with training-compatible versions
Searching for and disabling ALL gradient checkpointing in the model...
Disabled gradient checkpointing in 0 modules
Unfroze 10 FiLM parameter tensors
Total FiLM parameters: 1871616
Adapter has 1511936 trainable parameters
Total trainable parameters: 2644736
Modules in train mode: 13
Modules in eval mode: 2245
Saving checkpoints to run-specific directory: ckpt/vocaldm/dainty-cherry-78
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..

===== Running initial validation for baseline metrics =====
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Validation DataLoader 0:   0%|                                                                                                                                | 0/312 [00:00<?, ?it/s]Audio logging disabled (use --log_audio to enable)
DDIM Sampler: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:12<00:00,  3.31it/s]
/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /mnt/c/Users/Davy/Documents/Code/QM/CC/AudioLDM/ckpt/vocaldm/dainty-cherry-78 exists and is not empty.
Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 312/312 [05:22<00:00,  0.97it/s]
Saved improved adapter and FiLM parameters to ckpt/vocaldm/dainty-cherry-78/vocaldm_checkpoint_val_loss_0.6682.pt
Validation DataLoader 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 312/312 [05:23<00:00,  0.96it/s]
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m [0m[1m     Validate metric     [0m[1m [0m┃[1m [0m[1m      DataLoader 0       [0m[1m [0m┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│[36m [0m[36m     val/cosine_loss     [0m[36m [0m│[35m [0m[35m           0.0           [0m[35m [0m│
│[36m [0m[36m     val/epoch_loss      [0m[36m [0m│[35m [0m[35m   0.6690068244934082    [0m[35m [0m│
│[36m [0m[36m        val/loss         [0m[36m [0m│[35m [0m[35m   0.6681907773017883    [0m[35m [0m│
│[36m [0m[36m      val/mse_loss       [0m[36m [0m│[35m [0m[35m   0.6681907773017883    [0m[35m [0m│
│[36m [0m[36m        val_loss         [0m[36m [0m│[35m [0m[35m   0.6681907773017883    [0m[35m [0m│
└───────────────────────────┴───────────────────────────┘
Initial validation loss: 0.668191
===== Initial validation complete =====
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name       | Type            | Params | Mode
-------------------------------------------------------
0 | qvim_model | QVIMModule      | 9.8 M  | eval
1 | adapter    | QVIMAdapter     | 1.5 M  | train
2 | audioldm   | LatentDiffusion | 726 M  | eval
-------------------------------------------------------
2.6 M     Trainable params
734 M     Non-trainable params
737 M     Total params
2,949.710 Total estimated model params size (MB)
12        Modules in train mode
2245      Modules in eval mode

Sanity Checking DataLoader 0:   0%|                                                                                                                           | 0/312 [00:00<?, ?it/s]Audio logging disabled (use --log_audio to enable)
DDIM Sampler: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:11<00:00,  3.61it/s]
DDIM Sampler: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:11<00:00,  3.66it/s]
Sanity Checking DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 312/312 [05:25<00:00,  0.96it/s]
Saved improved adapter and FiLM parameters to ckpt/vocaldm/dainty-cherry-78/vocaldm_checkpoint_val_loss_0.6638.pt
Epoch 0:   0%|                                                                                                                                               | 0/2802 [00:00<?, ?it/s]diffusion_loss requires_grad: True
Checking gradient paths:
Component requires_grad check: {'squared_diff': True, 'model_output': True, 'target': False}
Optimizer parameter groups:
  Group 0: lr=0.0001, 8 parameters
  Group 1: lr=1e-05, 6 parameters
Epoch 0:   0%|                                                          | 1/2802 [00:04<3:44:42,  0.21it/s, v_num=z3bd, train/loss=0.709, train/adapter_lr=0.0001, train/film_lr=1e-5]Optimizer parameter groups:
  Group 0: lr=0.0001, 8 parameters
  Group 1: lr=1e-05, 6 parameters
Epoch 0:   0%|                                                          | 2/2802 [00:06<2:41:30,  0.29it/s, v_num=z3bd, train/loss=0.795, train/adapter_lr=0.0001, train/film_lr=1e-5]Optimizer parameter groups:
  Group 0: lr=0.0001, 8 parameters
  Group 1: lr=1e-05, 6 parameters
Epoch 0:   0%|                                                          | 3/2802 [00:06<1:41:11,  0.46it/s, v_num=z3bd, train/loss=0.567, train/adapter_lr=0.0001, train/film_lr=1e-5]Optimizer parameter groups:
  Group 0: lr=0.0001, 8 parameters
  Group 1: lr=1e-05, 6 parameters
Epoch 0:  23%|█████████████▍                                            | 650/2802 [14:46<48:56,  0.73it/s, v_num=z3bd, train/loss=0.532, train/adapter_lr=0.0001, train/film_lr=1e-5]Resources cleaned up
Detected KeyboardInterrupt, attempting graceful shutdown ...
