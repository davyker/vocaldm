Dataset directory ready at audioldm/qvim/data/Vim_Sketch_Dataset
Dataset directory ready at audioldm/qvim/data
Successfully loaded dataset with 12453 samples
Training with 11208 samples, validating with 1245 samples
Loading QVIM model from audioldm/qvim/models_vimsketch_longer/dulcet-leaf-31/best-loss-checkpoint.ckpt
Loading QVIM model from audioldm/qvim/models_vimsketch_longer/dulcet-leaf-31/best-loss-checkpoint.ckpt
Warning: FMAX is None setting to 15000
Initializing QVIM adapter: QVIM dim=960, AudioLDM dim=512
Loading AudioLDM model: audioldm-m-full
Load AudioLDM: %s audioldm-m-full
DiffusionWrapper has 415.95 M params.
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Traceback (most recent call last):
  File "/mnt/c/Users/Davy/Documents/Code/QM/CC/AudioLDM/train_vocaldm.py", line 1750, in <module>
    success = train_vocaldm(args)
  File "/mnt/c/Users/Davy/Documents/Code/QM/CC/AudioLDM/train_vocaldm.py", line 1317, in train_vocaldm
    model = VocaLDMModule(args)
  File "/mnt/c/Users/Davy/Documents/Code/QM/CC/AudioLDM/train_vocaldm.py", line 187, in __init__
    self.initialize_models()
  File "/mnt/c/Users/Davy/Documents/Code/QM/CC/AudioLDM/train_vocaldm.py", line 209, in initialize_models
    self.audioldm = load_audioldm_model_with_qvim_cond(model_source, device=self.device)
  File "/mnt/c/Users/Davy/Documents/Code/QM/CC/AudioLDM/vocaldm_utils.py", line 50, in load_audioldm_model_with_qvim_cond
    audioldm = build_model(model_name=model_name_or_path)
  File "/mnt/c/Users/Davy/Documents/Code/QM/CC/AudioLDM/audioldm/pipeline.py", line 166, in build_model
    latent_diffusion.load_state_dict(checkpoint["state_dict"], strict=False)
  File "/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2561, in load_state_dict
    load(self, state_dict)
  File "/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2549, in load
    load(child, child_state_dict, child_prefix)  # noqa: F821
  File "/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2549, in load
    load(child, child_state_dict, child_prefix)  # noqa: F821
  File "/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2549, in load
    load(child, child_state_dict, child_prefix)  # noqa: F821
  [Previous line repeated 4 more times]
  File "/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2532, in load
    module._load_from_state_dict(
  File "/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2438, in _load_from_state_dict
    param.copy_(input_param)
KeyboardInterrupt
Traceback (most recent call last):
  File "/mnt/c/Users/Davy/Documents/Code/QM/CC/AudioLDM/train_vocaldm.py", line 1750, in <module>
    success = train_vocaldm(args)
  File "/mnt/c/Users/Davy/Documents/Code/QM/CC/AudioLDM/train_vocaldm.py", line 1317, in train_vocaldm
    model = VocaLDMModule(args)
  File "/mnt/c/Users/Davy/Documents/Code/QM/CC/AudioLDM/train_vocaldm.py", line 187, in __init__
    self.initialize_models()
  File "/mnt/c/Users/Davy/Documents/Code/QM/CC/AudioLDM/train_vocaldm.py", line 209, in initialize_models
    self.audioldm = load_audioldm_model_with_qvim_cond(model_source, device=self.device)
  File "/mnt/c/Users/Davy/Documents/Code/QM/CC/AudioLDM/vocaldm_utils.py", line 50, in load_audioldm_model_with_qvim_cond
    audioldm = build_model(model_name=model_name_or_path)
  File "/mnt/c/Users/Davy/Documents/Code/QM/CC/AudioLDM/audioldm/pipeline.py", line 166, in build_model
    latent_diffusion.load_state_dict(checkpoint["state_dict"], strict=False)
  File "/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2561, in load_state_dict
    load(self, state_dict)
  File "/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2549, in load
    load(child, child_state_dict, child_prefix)  # noqa: F821
  File "/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2549, in load
    load(child, child_state_dict, child_prefix)  # noqa: F821
  File "/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2549, in load
    load(child, child_state_dict, child_prefix)  # noqa: F821
  [Previous line repeated 4 more times]
  File "/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2532, in load
    module._load_from_state_dict(
  File "/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/torch/nn/modules/module.py", line 2438, in _load_from_state_dict
    param.copy_(input_param)
KeyboardInterrupt
