audioldm/qvim/data/VimSketch.zip already exists. Skipping download. https://zenodo.org/records/2596911/files/Vim_Sketch_Dataset.zip?download=1
Vim_Sketch_Dataset already exists. Skipping extraction.
Dataset directory ready at audioldm/qvim/data
Successfully loaded dataset with 12453 samples
Training with 11208 samples, validating with 1245 samples
Loading QVIM model from audioldm/qvim/models_vimsketch_longer/dulcet-leaf-31/best-mrr-checkpoint.ckpt
Loading QVIM model from audioldm/qvim/models_vimsketch_longer/dulcet-leaf-31/best-mrr-checkpoint.ckpt
Warning: FMAX is None setting to 15000
/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/torchvision/ops/misc.py:120: UserWarning: Don't use ConvNormActivation directly, please use Conv2dNormActivation and Conv3dNormActivation instead.
  warnings.warn(
Initializing QVIM adapter: QVIM dim=960, AudioLDM dim=512
Loading AudioLDM model: audioldm-m-full
Load AudioLDM: %s audioldm-m-full
DiffusionWrapper has 415.95 M params.
/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/torchlibrosa/stft.py:193: FutureWarning: Pass size=1024 as keyword args. From version 0.10 passing these as positional arguments will result in an error
  fft_window = librosa.util.pad_center(fft_window, n_fft)
/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/torch/functional.py:539: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /home/conda/feedstock_root/build_artifacts/libtorch_1742923400330/work/aten/src/ATen/native/TensorShape.cpp:3637.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']
- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Replacing checkpoint function and CheckpointFunction class with training-compatible versions
Replacing get_first_stage_encoding method to preserve gradients
Searching for and disabling ALL gradient checkpointing in the model...
Disabled gradient checkpointing in 0 modules
Unfroze 10 FiLM parameter tensors
Total FiLM parameters: 1871616
Adapter has 1511936 trainable parameters
Total trainable parameters: 2644736
Modules in train mode: 13
Modules in eval mode: 2245
Saving checkpoints to run-specific directory: ckpt/vocaldm/treasured-sky-77
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..

===== Running initial validation for baseline metrics =====
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Validation DataLoader 0:   0%|                                                                                                                                                                                           | 0/312 [00:00<?, ?it/s]Audio logging disabled (use --log_audio to enable)
DDIM Sampler: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:12<00:00,  3.25it/s]
/root/miniconda3/envs/qvim-baseline/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /mnt/c/Users/Davy/Documents/Code/QM/CC/AudioLDM/ckpt/vocaldm/treasured-sky-77 exists and is not empty.
Validation DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 312/312 [04:10<00:00,  1.25it/s]                          
Saved improved adapter to ckpt/vocaldm/treasured-sky-77/qvim_adapter_val_loss_0.6682.pt
Validation DataLoader 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 312/312 [04:10<00:00,  1.24it/s]
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃[1m [0m[1m     Validate metric     [0m[1m [0m┃[1m [0m[1m      DataLoader 0       [0m[1m [0m┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│[36m [0m[36m     val/cosine_loss     [0m[36m [0m│[35m [0m[35m           0.0           [0m[35m [0m│
│[36m [0m[36m     val/epoch_loss      [0m[36m [0m│[35m [0m[35m   0.6690307855606079    [0m[35m [0m│
│[36m [0m[36m        val/loss         [0m[36m [0m│[35m [0m[35m   0.6682152152061462    [0m[35m [0m│
│[36m [0m[36m      val/mse_loss       [0m[36m [0m│[35m [0m[35m   0.6682152152061462    [0m[35m [0m│
│[36m [0m[36m        val_loss         [0m[36m [0m│[35m [0m[35m   0.6682152152061462    [0m[35m [0m│
└───────────────────────────┴───────────────────────────┘
Initial validation loss: 0.668215
===== Initial validation complete =====
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name       | Type            | Params | Mode
-------------------------------------------------------
0 | qvim_model | QVIMModule      | 9.8 M  | eval
1 | adapter    | QVIMAdapter     | 1.5 M  | train
2 | audioldm   | LatentDiffusion | 726 M  | eval
-------------------------------------------------------
2.6 M     Trainable params
734 M     Non-trainable params
737 M     Total params
2,949.710 Total estimated model params size (MB)
12        Modules in train mode
2245      Modules in eval mode

Sanity Checking DataLoader 0:   0%|                                                                                                                                                                                              | 0/312 [00:00<?, ?it/s]Audio logging disabled (use --log_audio to enable)
DDIM Sampler: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:09<00:00,  4.19it/s]
DDIM Sampler: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:09<00:00,  3.96it/s]
Sanity Checking DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 312/312 [04:06<00:00,  1.27it/s]
Saved improved adapter to ckpt/vocaldm/treasured-sky-77/qvim_adapter_val_loss_0.6638.pt
Epoch 0:   0%|                                                                                                                                                                                                                  | 0/2802 [00:00<?, ?it/s]diffusion_loss requires_grad: True
Checking gradient paths:
Component requires_grad check: {'squared_diff': True, 'model_output': True, 'target': False}
Optimizer parameter groups:
  Group 0: lr=0.0001, 8 parameters
  Group 1: lr=1e-05, 6 parameters
Step 0 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:   0%|                                                                                                                             | 1/2802 [00:03<2:55:57,  0.27it/s, v_num=y71h, train/loss=0.709, train/adapter_lr=0.0001, train/film_lr=1e-5]Optimizer parameter groups:
  Group 0: lr=0.0001, 8 parameters
  Group 1: lr=1e-05, 6 parameters
Step 0 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:   0%|                                                                                                                             | 2/2802 [00:05<1:59:29,  0.39it/s, v_num=y71h, train/loss=0.796, train/adapter_lr=0.0001, train/film_lr=1e-5]Optimizer parameter groups:
  Group 0: lr=0.0001, 8 parameters
  Group 1: lr=1e-05, 6 parameters
Step 0 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:   0%|▏                                                                                                                            | 3/2802 [00:06<1:40:45,  0.46it/s, v_num=y71h, train/loss=0.566, train/adapter_lr=0.0001, train/film_lr=1e-5]Optimizer parameter groups:
  Group 0: lr=0.0001, 8 parameters
  Group 1: lr=1e-05, 6 parameters
Step 0 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  14%|█████████████████▊                                                                                                           | 400/2802 [09:20<56:06,  0.71it/s, v_num=y71h, train/loss=0.864, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 100 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  14%|█████████████████▉                                                                                                           | 401/2802 [09:22<56:05,  0.71it/s, v_num=y71h, train/loss=0.462, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 100 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  14%|█████████████████▉                                                                                                           | 402/2802 [09:23<56:04,  0.71it/s, v_num=y71h, train/loss=0.805, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 100 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  14%|█████████████████▉                                                                                                           | 403/2802 [09:24<56:03,  0.71it/s, v_num=y71h, train/loss=0.367, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 100 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  29%|███████████████████████████████████▋                                                                                         | 800/2802 [18:14<45:39,  0.73it/s, v_num=y71h, train/loss=0.541, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 200 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  29%|███████████████████████████████████▋                                                                                         | 801/2802 [18:14<45:35,  0.73it/s, v_num=y71h, train/loss=0.847, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 200 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  29%|███████████████████████████████████▊                                                                                         | 802/2802 [18:16<45:33,  0.73it/s, v_num=y71h, train/loss=0.999, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 200 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  29%|███████████████████████████████████▊                                                                                         | 803/2802 [18:17<45:32,  0.73it/s, v_num=y71h, train/loss=0.676, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 200 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  43%|█████████████████████████████████████████████████████                                                                       | 1200/2802 [32:49<43:49,  0.61it/s, v_num=y71h, train/loss=0.481, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 300 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  43%|█████████████████████████████████████████████████████▏                                                                      | 1201/2802 [32:51<43:48,  0.61it/s, v_num=y71h, train/loss=0.664, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 300 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  43%|█████████████████████████████████████████████████████▏                                                                      | 1202/2802 [32:54<43:47,  0.61it/s, v_num=y71h, train/loss=0.654, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 300 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  43%|█████████████████████████████████████████████████████▏                                                                      | 1203/2802 [32:56<43:47,  0.61it/s, v_num=y71h, train/loss=0.946, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 300 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  57%|██████████████████████████████████████████████████████████████████████▊                                                     | 1600/2802 [48:27<36:23,  0.55it/s, v_num=y71h, train/loss=0.534, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 400 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  57%|██████████████████████████████████████████████████████████████████████▊                                                     | 1601/2802 [48:29<36:22,  0.55it/s, v_num=y71h, train/loss=0.723, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 400 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  57%|██████████████████████████████████████████████████████████████████████▉                                                     | 1602/2802 [48:31<36:21,  0.55it/s, v_num=y71h, train/loss=0.646, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 400 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  57%|██████████████████████████████████████████████████████████████████████▉                                                     | 1603/2802 [48:34<36:19,  0.55it/s, v_num=y71h, train/loss=0.150, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 400 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  71%|███████████████████████████████████████████████████████████████████████████████████████                                   | 2000/2802 [1:03:55<25:37,  0.52it/s, v_num=y71h, train/loss=0.560, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 500 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  71%|███████████████████████████████████████████████████████████████████████████████████████                                   | 2001/2802 [1:03:57<25:36,  0.52it/s, v_num=y71h, train/loss=0.524, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 500 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  71%|███████████████████████████████████████████████████████████████████████████████████████▏                                  | 2002/2802 [1:03:59<25:34,  0.52it/s, v_num=y71h, train/loss=0.526, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 500 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  71%|███████████████████████████████████████████████████████████████████████████████████████▏                                  | 2003/2802 [1:04:02<25:32,  0.52it/s, v_num=y71h, train/loss=0.459, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 500 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  86%|████████████████████████████████████████████████████████████████████████████████████████████████████████▍                 | 2400/2802 [1:48:14<18:07,  0.37it/s, v_num=y71h, train/loss=0.523, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 600 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  86%|████████████████████████████████████████████████████████████████████████████████████████████████████████▌                 | 2401/2802 [1:48:17<18:05,  0.37it/s, v_num=y71h, train/loss=0.758, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 600 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  86%|████████████████████████████████████████████████████████████████████████████████████████████████████████▌                 | 2402/2802 [1:48:19<18:02,  0.37it/s, v_num=y71h, train/loss=0.905, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 600 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0:  86%|████████████████████████████████████████████████████████████████████████████████████████████████████████▋                 | 2403/2802 [1:48:22<17:59,  0.37it/s, v_num=y71h, train/loss=0.371, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 600 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 2800/2802 [5:37:11<00:14,  0.14it/s, v_num=y71h, train/loss=0.874, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 700 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉| 2801/2802 [5:37:13<00:07,  0.14it/s, v_num=y71h, train/loss=0.549, train/adapter_lr=0.0001, train/film_lr=1e-5]Step 700 LRs - Adapter: 0.00010000, Film: 0.00001000
Epoch 0: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2802/2802 [5:37:15<00:00,  0.14it/s, v_num=y71h, train/loss=0.687, train/adapter_lr=0.0001, train/film_lr=1e-5]
